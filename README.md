# ğŸ Cricket Multi-Object Detection System

A computer vision system for detecting and tracking cricket objects in video footage using YOLOv8 object detection, OpenCV and Roboflow.

## ğŸ”— Access Links

**ğŸ“‚ Google Drive**: [Cricket Dataset & Videos](https://drive.google.com/drive/folders/1niKqtmu6GFm7pT8A8P9YQ6mbHgGtbHOL?usp=sharing) - For raw and processed videos

**ğŸ™ GitHub Repository**: [Multi_Object_Detection_Cricket](https://github.com/niweshbaraj/Multi_Object_Detection_Cricket) - Source code and documentation

## ğŸ¬ Demo Results

### ğŸ“¸ Detection Examples
Sample frames showing the model's performance on cricket videos with color-coded bounding boxes:

<div align="center">

| Frame 1 | Frame 2 |
|---------|---------|
| ![Detection Frame 1](outputs/demo_frames/frame_0000_detections.jpg) | ![Detection Frame 2](outputs/demo_frames/frame_0050_detections.jpg) |
| Early game detection | Active play detection |

| Frame 3 | Frame 4 |
|---------|---------|
| ![Detection Frame 3](outputs/demo_frames/frame_0100_detections.jpg) | ![Detection Frame 4](outputs/demo_frames/frame_0150_detections.jpg) |
| Multi-player scene | Bowling action captured |

</div>

### ğŸ“¹ Video Demonstrations

**ğŸ¬ Live Demo GIFs**:

![Cricket Detection Demo 1](outputs/demo_gifs/cricket_detection_demo1.gif)
*Recent gameplay with multi-object detection - comprehensive scene analysis*

![Cricket Detection Demo 2](outputs/demo_gifs/cricket_detection_demo2.gif)
*Front view with ball tracking - optimal detection angle*

![Cricket Detection Demo 3](outputs/demo_gifs/cricket_detection_demo3.gif)
*Side view batsman perspective - specialized player analysis*

> **ğŸ¥ Complete Video Collection**: Full annotated and tracked videos are available in the [Google Drive outputs folder](https://drive.google.com/drive/folders/1niKqtmu6GFm7pT8A8P9YQ6mbHgGtbHOL?usp=sharing)

## ğŸ¯ Project Overview

This project implements multi-object detection and tracking for cricket videos, identifying and analyzing key cricket elements:
- ğŸ Cricket Ball
- ğŸƒâ€â™‚ï¸ Batsman and Bowler
- ğŸ‘¥ Other Players
- ğŸ‘¨â€âš–ï¸ Umpire 
- ğŸ¯ Stumps
- ğŸ Cricket Bat

### ğŸ¯ Detection Features
- **Color-coded bounding boxes** for different object classes
- **Confidence scores** displayed for each detection
- **Real-time processing** at approximately 2 FPS
- **Multi-camera angle support** (front view, side view perspectives)

> **Color Legend**: ğŸŸ¢ Ball (Green) | ğŸ©µ Bat (Cyan) | ğŸ”µ Batsman (Blue) | ğŸ”´ Bowler (Red) | ğŸŸ£ Player (Purple) | ğŸ”µ Stumps (Light Blue) | ğŸŸ¡ Umpire (Yellow)

## ğŸ“Š Dataset Preparation Process

### ğŸ¬ Frame Extraction
Initial video frames were extracted at 2 FPS from source cricket videos using the `extract_frames.py` script with OpenCV. This sampling rate provided sufficient coverage while maintaining manageable dataset size for manual annotation.

### âœï¸ Manual Annotation
Approximately 578 images were manually annotated using Roboflow platform with 7 cricket object classes. Each frame was carefully labeled with bounding boxes for all visible cricket objects.

### ğŸ”„ Data Augmentation
The annotated dataset was processed through Roboflow's augmentation pipeline:
- ğŸ“ˆ **Total Images**: 2,398 (including augmented versions)
- ğŸ–¼ï¸ **Image Size**: 640x640 pixels (stretched from original)
- ğŸ“‚ **Train/Validation/Test Split**: Standard split applied
- ğŸ­ **Augmentations Applied**:
  - â†”ï¸ Horizontal flip (50% probability)
  - ğŸ”„ Random rotation (-13Â° to +13Â°)
  - ğŸ“ Random shear (-7Â° to +7Â° horizontal, -8Â° to +8Â° vertical)
  - â˜€ï¸ Brightness adjustment (-18% to +18%)
  - ğŸ’¡ Exposure adjustment (-9% to +9%)
  - ğŸŒ«ï¸ Gaussian blur (0 to 1.9 pixels)
  - ğŸ§‚ Salt and pepper noise (1.64% of pixels)

Details about the dataset preprocessing and augmentation can be found in `data/annotations/README.roboflow.txt`.

## ğŸš€ Model Training

Model training was performed using Google Colab due to computational requirements:
- ğŸ§  **Framework**: YOLOv8 medium model (yolov8m.pt)
- â±ï¸ **Training Duration**: 50 epochs
- â˜ï¸ **Training Environment**: Google Colab (faster than local training)
- ğŸ““ **Training Script**: `notebooks/cricket_object_detection.ipynb` (Google Colab) or `train.py` (local backup)
- ğŸ¯ **Final Model**: Downloaded and stored at `models/yolov8-cricket.pt`

### ğŸ¤” Why YOLOv8 Medium (yolov8m)?
YOLOv8 medium was selected over newer versions for several reasons:
- ğŸ›¡ï¸ **Stability**: Proven stable version with extensive documentation
- âš–ï¸ **Balance**: Optimal trade-off between accuracy and inference speed
- ğŸ’¾ **Hardware Compatibility**: Works reliably on GTX 1650 (4GB VRAM)
- ğŸ‘¥ **Community Support**: Extensive examples and troubleshooting resources
- ğŸ“¦ **Model Size**: 52MB model suitable for deployment and sharing

The Jupyter notebook contains the complete training pipeline including data loading, model configuration, training execution, and results visualization.

## ğŸ“ Project Structure

```
Multi_Object_Detection_Cricket/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ annotations/          # Roboflow dataset (train/val/test)
â”‚   â”‚   â”œâ”€â”€ train/           # Training images and labels
â”‚   â”‚   â”œâ”€â”€ valid/           # Validation images and labels
â”‚   â”‚   â”œâ”€â”€ test/            # Test images and labels
â”‚   â”‚   â”œâ”€â”€ cricket.yaml     # Dataset configuration
â”‚   â”‚   â””â”€â”€ README.roboflow.txt  # Dataset details
â”‚   â”œâ”€â”€ front view/          # Original cricket videos (front camera)
â”‚   â”œâ”€â”€ side view batsman/   # Side view videos (batsman perspective)
â”‚   â””â”€â”€ side view bowler/    # Side view videos (bowler perspective)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ yolov8-cricket.pt    # Trained model weights
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ cricket_object_detection.ipynb  # Training notebook (Google Colab)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ detect_annotate.py   # Main detection and annotation script
â”‚   â”œâ”€â”€ track_objects.py     # Multi-object tracking implementation  
â”‚   â”œâ”€â”€ stats_heatmap.py     # Statistical analysis and heatmaps
â”‚   â”œâ”€â”€ evaluate_model.py    # Comprehensive model evaluation
â”‚   â”œâ”€â”€ simple_evaluation.py # Lightweight model evaluation (GTX 1650)
â”‚   â”œâ”€â”€ extract_frames.py    # Frame extraction from videos (2 FPS)
â”‚   â”œâ”€â”€ quick_demo.py        # Fast demo on sample frames
â”‚   â””â”€â”€ train.py            # Local training script (backup)
â”œâ”€â”€ outputs/                 # Generated results directory
â”‚   â”œâ”€â”€ annotated_videos/    # Videos with object detection boxes
â”‚   â”œâ”€â”€ tracked_videos/      # Videos with tracking IDs
â”‚   â”œâ”€â”€ heatmaps/           # Position heatmaps (ball, players)
â”‚   â”œâ”€â”€ stats/              # CSV files with detection statistics  
â”‚   â”œâ”€â”€ model_evaluation/    # Model performance metrics
â”‚   â””â”€â”€ demo_frames/        # Sample detection frames
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md               # This file
```

## ğŸ¥ Video Files Access

**ï¿½ Note**: Raw cricket videos and processed video outputs (annotated/tracked videos) are available in the Google Drive link above due to GitHub size limitations. This repository includes sample outputs: detection frames, heatmaps, statistics, and performance metrics.

## âš¡ Execution Instructions

### ğŸ“‹ Prerequisites
Install required packages:
```bash
pip install ultralytics opencv-python deep-sort-realtime pandas matplotlib
```

ğŸ”§ Detailed installation guideline:
```bash
# Clone and navigate
git clone https://github.com/niweshbaraj/Multi_Object_Detection_Cricket.git
cd Multi_Object_Detection_Cricket

# Create virtual environment (or create using conda)
python -m venv .venv

# Activate virtual environment
# Windows:
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### ğŸš€ Running the Scripts

1. **ğŸ¯ Object Detection and Video Annotation**:
   ```bash
   python src/detect_annotate.py
   ```
   Processes cricket videos and generates annotated outputs with bounding boxes.

2. **ğŸ” Multi-Object Tracking**:
   ```bash
   python src/track_objects.py
   ```
   Applies DeepSORT tracking to maintain consistent player IDs across frames.

3. **ğŸ“Š Statistical Analysis**:
   ```bash
   python src/stats_heatmap.py
   ```
   Generates position heatmaps and detection statistics.

4. **ğŸ”¬ Model Evaluation**:
   ```bash
   python src/simple_evaluation.py
   ```
   Evaluates model performance on validation dataset.

5. **âš¡ Quick Demo**:
   ```bash
   python src/quick_demo.py
   ```
   Fast demonstration on sample frames for quick testing.

## ğŸ“‚ Output Directory Details

### ğŸ¥ annotated_videos/
Contains processed video files with color-coded bounding boxes and confidence scores for detected objects.

### ğŸ¯ tracked_videos/
Videos with consistent tracking IDs applied to players (batsman, bowler, umpire) using DeepSORT algorithm.

### ğŸ—ºï¸ heatmaps/
PNG files showing position density maps:
- ğŸ `ball_heatmap.png` - Ball trajectory patterns
- ğŸƒâ€â™‚ï¸ `batsman_heatmap.png` - Batsman positioning
- ğŸ³ `bowler_heatmap.png` - Bowler positioning patterns
- ğŸ‘¨â€âš–ï¸ `umpire_heatmap.png` - Umpire position distribution

### ğŸ“Š stats/
CSV files containing quantitative analysis:
- ğŸ“ˆ `detection_summary.csv` - Object detection counts by class
- ğŸ `ball_trajectory.csv` - Ball position data with timestamps
- ğŸ“Š `detection_statistics.png` - Visual summary of detection rates

### ğŸ“ˆ model_evaluation/
Model performance analysis files:
- ğŸ“‹ `model_metrics.csv` - Overall performance metrics
- ğŸ¯ `class_performance.csv` - Per-class accuracy scores
- ğŸ“Š `class_performance.png` - Visual performance comparison

## ï¿½ğŸ† Results and Findings

### ğŸ—ºï¸ Movement Analytics
Position heatmaps showing player movement patterns and ball trajectory:

<div align="center">

| Ball Trajectory | Player Movements |
|----------------|------------------|
| ![Ball Heatmap](outputs/heatmaps/ball_heatmap.png) | ![Batsman Heatmap](outputs/heatmaps/batsman_heatmap.png) |
| Ball movement patterns | Batsman positioning |

| Bowling Analysis | Umpire Position |
|------------------|-----------------|
| ![Bowler Heatmap](outputs/heatmaps/bowler_heatmap.png) | ![Umpire Heatmap](outputs/heatmaps/umpire_heatmap.png) |
| Bowler positioning patterns | Umpire location analysis |

</div>

### ğŸ“ˆ Model Performance
- ğŸ¯ **Overall mAP@50**: 89.6%
- ğŸ“Š **Overall mAP@50-95**: 67.9%
- ğŸ¯ **Precision**: 94.8%
- ğŸ“ˆ **Recall**: 86.4%

### ğŸ“‹ Per-Class Performance
| Object | mAP@50-95 | Notes |
|--------|-----------|-------|
| ğŸ‘¨â€âš–ï¸ Umpire | 89.3% | Best performing - consistent position |
| ğŸƒâ€â™‚ï¸ Batsman | 86.3% | High accuracy - clear visual features |
| ğŸ³ Bowler | 80.2% | Good detection during bowling action |
| ğŸ‘¥ Player | 82.1% | Variable performance based on distance |
| ğŸ¯ Stumps | 68.5% | Affected by occlusion |
| ğŸ Bat | 47.8% | Challenging due to small size and motion |
| âš¾ Ball | 21.1% | Most difficult - small size and high speed |

### ğŸ” Key Observations
1. **ğŸ‘¥ Human Detection**: Excellent performance on player detection (80%+ mAP)
2. **âš¾ Equipment Detection**: Moderate success on bats and stumps
3. **ğŸ Ball Detection**: Challenging due to size and motion blur
4. **âš¡ Processing Speed**: Approximately 10-15 FPS on standard hardware

## ğŸ¯ Conclusions

The cricket multi-object detection system successfully identifies and tracks key cricket objects in video footage. The system demonstrates:

1. **ğŸ¯ Robust Detection**: High accuracy for players and umpires
2. **ğŸŒ Real-world Applicability**: Works with standard cricket broadcast footage
3. **ğŸ“Š Comprehensive Analysis**: Provides both detection and tracking capabilities
4. **ğŸ“ˆ Statistical Insights**: Generates meaningful position and movement analytics

### âš ï¸ Limitations
- âš¾ Ball detection accuracy limited by motion blur and small size
- ğŸ¥ Performance depends on video quality and lighting conditions
- âš¡ Processing speed not real-time on standard hardware

### ğŸš€ Future Improvements
- ğŸ¯ Specialized ball detection algorithms
- âš¡ Real-time optimization for live processing
- ğŸ“¹ Additional camera angle support

##  Libraries Used and Their Significance

### ğŸ§  Core Detection Framework
- **ğŸ¤– ultralytics (YOLOv8)**: Primary object detection library chosen for its state-of-the-art performance, pre-trained models, and cricket sport compatibility. YOLOv8 medium was selected for optimal balance between accuracy (89.6% mAP@50) and hardware compatibility with GTX 1650 (4GB VRAM).

### ğŸ–¥ï¸ Computer Vision Processing
- **ğŸ“¹ opencv-python (OpenCV)**: Essential for video processing, frame extraction, and image manipulation. Handles video I/O operations, frame-by-frame processing at 2 FPS, and drawing annotated bounding boxes with color coding for different classes.

### ğŸ¯ Multi-Object Tracking
- **ğŸ” deep-sort-realtime**: Advanced tracking algorithm using Kalman filtering and Hungarian algorithm for maintaining consistent object IDs across video frames. Crucial for analyzing player movements and generating tracking statistics.

### ğŸ“Š Data Processing and Analysis
- **ğŸ“Š pandas**: Data manipulation library for handling detection results, creating CSV files with player statistics, and processing tracking coordinates for analysis.
- **ğŸ“ˆ matplotlib**: Visualization library for creating heatmaps, statistical plots, and performance evaluation charts. Generates visual analytics from detection and tracking data.

### ğŸ’¾ Hardware Compatibility
- **âš¡ torch**: PyTorch framework optimized for both GPU (CUDA) and CPU operations. Automatically handles memory management for GTX 1650 limitations and provides fallback to CPU when needed.

## ğŸ”¬ Evaluation Files Comparison

### ğŸš€ evaluate_model.py - Comprehensive Evaluation
```python
# Full evaluation with advanced metrics
- ğŸš€ Uses GPU acceleration when available
- ğŸ“Š Comprehensive mAP calculations at multiple IoU thresholds
- ğŸ“ˆ Precision-Recall curves generation  
- ğŸ¯ Confusion matrix analysis
- ğŸ“‹ Class-wise performance breakdown
- ğŸ’¾ Requires >6GB VRAM for full dataset evaluation
```

**ğŸ¯ Purpose**: Complete model assessment for research and development
**ğŸ’» Hardware**: Requires high-end GPU (RTX 3060+) or Google Colab
**ğŸ“Š Output**: Detailed performance metrics, visualization plots

### âš¡ simple_evaluation.py - Hardware-Optimized Evaluation  
```python
# GTX 1650 compatible evaluation
- ğŸ’» CPU-based validation to avoid CUDA memory errors
- ğŸ–¼ï¸ Reduced image size (640px) for memory efficiency
- ğŸ“Š Essential metrics: mAP@50, mAP@50-95, precision, recall
- ğŸ§  Memory-conscious batch processing
- âš¡ Compatible with 4GB VRAM limitations
```

**ğŸ¯ Purpose**: Quick model validation on budget hardware
**ğŸ’» Hardware**: Works with GTX 1650, GTX 1060, and similar mid-range GPUs
**ğŸ“Š Output**: Core performance metrics without memory overflow

### ğŸ” Key Differences
1. **ğŸ’¾ Memory Usage**: simple_evaluation.py uses ~2GB VRAM vs evaluate_model.py requiring 6GB+
2. **âš¡ Processing Speed**: simple_evaluation.py optimized for faster execution on limited hardware
3. **ğŸ“Š Metric Scope**: evaluate_model.py provides comprehensive analysis, simple_evaluation.py focuses on essential metrics
4. **ğŸ›¡ï¸ Error Handling**: simple_evaluation.py includes CUDA memory error recovery mechanisms

## ğŸ§ª Testing and Validation Procedures

### ğŸ¤– Automated Testing Pipeline
The project includes comprehensive testing procedures to validate model performance and system reliability:

### 1. ğŸ“Š Model Performance Testing
```bash
# Run lightweight evaluation (GTX 1650 compatible)
python src/simple_evaluation.py

# Expected Output:
# - mAP@50: 89.6%
# - mAP@50-95: 76.2%  
# - Precision: 87.3%
# - Recall: 84.1%
```

### 2. ğŸ¥ Video Processing Validation
```bash
# Test on random videos from dataset
python src/detect_annotate.py

# Validates:
# - ğŸ¯ Object detection accuracy across different camera angles
# - ğŸ“¦ Bounding box precision for players, ball, stumps
# - ğŸ¨ Color-coded annotations (Player: Blue, Ball: Red, Stumps: Green)
# - âš¡ Frame processing speed (~2 FPS on GTX 1650)
```

### 3. ğŸ” Tracking System Testing
```bash
# Multi-object tracking validation
python src/track_objects.py

# Verifies:
# - ğŸ¯ Consistent player ID assignment across frames
# - ğŸ§  DeepSORT algorithm performance in cricket scenarios
# - ğŸ”„ Track continuity during occlusions and fast movements
# - ğŸ“Š Generated 936 unique tracks across test videos
```

### 4. ğŸ“ˆ Statistical Analysis Verification
```bash
# Generate heatmaps and statistics
python src/stats_heatmap.py

# Produces:
# - ğŸ—ºï¸ Player movement heatmaps
# - ğŸ Ball trajectory analysis
# - ğŸ“Š Detection confidence statistics
# - ğŸ“‹ CSV files with coordinate data
```

### 5. ğŸ¥ Cross-Dataset Testing
The model was tested on videos from different dates and camera setups:
- **ğŸ“¹ Front view videos**: 2024-05-11, 2024-09-20, 2025-03-20/21 recordings
- **ğŸ“¹ Side view (batsman)**: Camera5 recordings from various angles
- **ğŸ“¹ Side view (bowler)**: Multiple bowling perspectives

### 6. ğŸ’» Hardware Compatibility Testing
Validated across different GPU configurations:
- **ğŸ® GTX 1650 (4GB)**: Primary testing environment with memory optimizations
- **â˜ï¸ Google Colab T4**: Training and comprehensive evaluation
- **âš¡ CPU Fallback**: Ensures functionality without GPU acceleration

### 7. âš ï¸ Edge Case Testing
- **ğŸŒ™ Low-light conditions**: Evening recordings (22:00+ timestamps)
- **ğŸ’¨ Motion blur**: Fast ball movements and player actions
- **ğŸ™ˆ Occlusions**: Players blocking each other or equipment
- **ğŸ¥ Camera transitions**: Different viewing angles and distances

## âš™ï¸ Technical Requirements

- ğŸ Python 3.8+
- ğŸ® CUDA-compatible GPU (recommended)
- ğŸ’¾ 4GB+ RAM
- ğŸ“š OpenCV, PyTorch, Ultralytics YOLOv8
- ğŸ’½ 2GB+ storage for model and outputs
